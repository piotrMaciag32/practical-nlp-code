{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:47:16.018340Z",
     "start_time": "2023-05-15T21:47:15.985095Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = 'Consider a scenario where we’re working with a collection of social media posts to detect news events. Social media text is very different from the language we’d see in, say, newspapers. A word can be spelled in different ways, including in shortened forms, a phone number can be written in different formats (e.g., with and without hyphens), names are sometimes in lowercase, and so on. When we’re working on developing NLP tools to work with such data, it’s useful to reach a canonical representation of text that captures all these variations into one representation. This is known as text normalization. Some common steps for text normalization are to convert all text to lowercase or uppercase, convert digits to text (e.g., 9 to nine), expand abbreviations, and so on. A simple way to incorporate text normalization can be found in Spacy’s source code [35], which is a dictionary showing different spellings of a preset collection of words mapped to a single spelling. We’ll see more examples of text normalization in Chapter 8.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consider a scenario where we’re working with a collection of social media posts to detect news events. social media text is very different from the language we’d see in, say, newspapers. a word can be spelled in different ways, including in shortened forms, a phone number can be written in different formats (e.g., with and without hyphens), names are sometimes in lowercase, and so on. when we’re working on developing nlp tools to work with such data, it’s useful to reach a canonical representation of text that captures all these variations into one representation. this is known as text normalization. some common steps for text normalization are to convert all text to lowercase or uppercase, convert digits to text (e.g., 9 to nine), expand abbreviations, and so on. a simple way to incorporate text normalization can be found in spacy’s source code [35], which is a dictionary showing different spellings of a preset collection of words mapped to a single spelling. we’ll see more examples of text normalization in chapter 8.\n"
     ]
    }
   ],
   "source": [
    "corpus_lower = corpus.lower()\n",
    "print(corpus_lower)\n",
    "\n",
    "import re\n",
    "corpus_lower = re.sub(r'\\d+','', corpus_lower)\n",
    "import string\n",
    "corpus_lower = corpus_lower.translate(str.maketrans('', '', string.punctuation))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:47:19.047806Z",
     "start_time": "2023-05-15T21:47:19.043102Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'variations', 'as', 'posts', 'written', 'see', 'reach', 'digits', 'words', 'it', 'expand', 'media', 'formats', 'convert', 'all', 'with', 'events', 'newspapers', 'word', 'abbreviations', 'sometimes', 'language', 'be', 'normalization', 'that', 'd', 'useful', 'more', 'and', 'is', 'detect', 'these', 'found', 'steps', 'shortened', 'some', 'into', 'data', 'lowercase', 'way', 'collection', 'mapped', 'phone', 'names', 'working', 'simple', 'scenario', 'uppercase', 'spacy', 'which', 'captures', 'different', 'this', 'spellings', 'we', 'showing', 'say', 's', 'common', 'on', 'without', 'canonical', 'tools', 're', 'very', 'code', 'forms', 'single', 'spelled', 'when', 'such', 'dictionary', 'or', '’', 'can', 'eg', 'social', 'text', 'a', 'spelling', 'hyphens', 'examples', 'to', 'representation', 'so', 'number', 'from', 'consider', 'for', 'ways', 'incorporate', 'the', 'chapter', 'news', 'll', 'source', 'preset', 'work', 'known', 'including', 'nlp', 'where', 'one', 'nine', 'of', 'in', 'developing', 'are'}\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_nltk = set(stopwords.words('english'))\n",
    "\n",
    "tokens = set(word_tokenize(corpus_lower))\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:47:21.616286Z",
     "start_time": "2023-05-15T21:47:21.015272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'showing', 'useful', 'variations', 'posts', 'written', 'say', 'spelling', 'see', 'hyphens', 'detect', 'reach', 'digits', 'words', 'found', 'common', 'examples', 'steps', 'shortened', 'representation', 'number', 'without', 'data', 'expand', 'canonical', 'media', 'lowercase', 'tools', 'formats', 'consider', 'way', 'collection', 'convert', 'ways', 'mapped', 'incorporate', 'code', 'forms', 'chapter', 'news', 'single', 'events', 'newspapers', 'phone', 'spelled', 'names', 'working', 'word', 'abbreviations', 'simple', 'scenario', 'source', 'preset', 'work', 'uppercase', 'dictionary', 'known', 'including', 'sometimes', 'nlp', '’', 'one', 'spacy', 'nine', 'captures', 'language', 'different', 'eg', 'social', 'text', 'normalization', 'developing', 'spellings'}\n"
     ]
    }
   ],
   "source": [
    "tokens_no_stop = tokens - stop_words_nltk\n",
    "print(tokens_no_stop)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:47:24.002951Z",
     "start_time": "2023-05-15T21:47:23.999322Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/piotr/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Before Stemming:\n",
      "{'convert', 'examples', 'written', 'one', 'steps', 'scenario', 'nine', 'uppercase', 'reach', 'dictionary', 'representation', 'language', 'simple', 'spacy', 'detect', 'phone', 'names', 'expand', 'media', 'shortened', 'without', 'captures', 'work', 'collection', 'news', 'working', 'spelled', 'including', 'common', 'ways', 'chapter', 'mapped', 'different', 'developing', 'useful', 'normalization', 'single', 'posts', 'tools', 'consider', 'forms', 'code', 'found', 'eg', 'data', 'digits', 'hyphens', 'text', 'see', 'known', 'events', 'words', 'number', 'sometimes', 'showing', 'newspapers', 'formats', 'preset', 'say', 'spelling', 'spellings', 'canonical', '’', 'source', 'nlp', 'way', 'social', 'variations', 'word', 'incorporate', 'abbreviations', 'lowercase'}\n",
      "After Stemming:\n",
      "convert exampl written one step scenario nine uppercas reach dictionari represent languag simpl spaci detect phone name expand media shorten without captur work collect news work spell includ common way chapter map differ develop use normal singl post tool consid form code found eg data digit hyphen text see known event word number sometim show newspap format preset say spell spell canon ’ sourc nlp way social variat word incorpor abbrevi lowercas "
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "stemmer= PorterStemmer()\n",
    "\n",
    "print(\"Before Stemming:\")\n",
    "print(tokens_no_stop)\n",
    "\n",
    "print(\"After Stemming:\")\n",
    "for word in tokens_no_stop:\n",
    "    print(stemmer.stem(word),end=\" \")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:25:51.127044Z",
     "start_time": "2023-05-15T21:25:51.122338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['showing', 'useful', 'variation', 'post', 'written', 'say', 'spelling', 'see', 'hyphen', 'detect', 'reach', 'digit', 'word', 'found', 'common', 'example', 'step', 'shortened', 'representation', 'number', 'without', 'data', 'expand', 'canonical', 'medium', 'lowercase', 'tool', 'format', 'consider', 'way', 'collection', 'convert', 'way', 'mapped', 'incorporate', 'code', 'form', 'chapter', 'news', 'single', 'event', 'newspaper', 'phone', 'spelled', 'name', 'working', 'word', 'abbreviation', 'simple', 'scenario', 'source', 'preset', 'work', 'uppercase', 'dictionary', 'known', 'including', 'sometimes', 'nlp', '’', 'one', 'spacy', 'nine', 'capture', 'language', 'different', 'eg', 'social', 'text', 'normalization', 'developing', 'spelling']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.tokenize import word_tokenize\n",
    "# nltk.download('wordnet')\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "for word in tokens_no_stop:\n",
    "    print(lemmatizer.lemmatize(word),end=\" \")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:48:41.228996Z",
     "start_time": "2023-05-15T21:48:40.643723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[('showing', 'VBG'),\n ('useful', 'JJ'),\n ('variation', 'NN'),\n ('post', 'NN'),\n ('written', 'VBN'),\n ('say', 'VBP'),\n ('spelling', 'VBG'),\n ('see', 'NN'),\n ('hyphen', 'NN'),\n ('detect', 'VB'),\n ('reach', 'NN'),\n ('digit', 'NN'),\n ('word', 'NN'),\n ('found', 'VBD'),\n ('common', 'JJ'),\n ('example', 'NN'),\n ('step', 'NN'),\n ('shortened', 'VBD'),\n ('representation', 'NN'),\n ('number', 'NN'),\n ('without', 'IN'),\n ('data', 'NNS'),\n ('expand', 'RB'),\n ('canonical', 'JJ'),\n ('medium', 'NN'),\n ('lowercase', 'NN'),\n ('tool', 'NN'),\n ('format', 'NN'),\n ('consider', 'VB'),\n ('way', 'NN'),\n ('collection', 'NN'),\n ('convert', 'VBP'),\n ('way', 'NN'),\n ('mapped', 'JJ'),\n ('incorporate', 'NN'),\n ('code', 'NN'),\n ('form', 'NN'),\n ('chapter', 'NN'),\n ('news', 'NN'),\n ('single', 'JJ'),\n ('event', 'NN'),\n ('newspaper', 'NN'),\n ('phone', 'NN'),\n ('spelled', 'VBD'),\n ('name', 'NN'),\n ('working', 'VBG'),\n ('word', 'NN'),\n ('abbreviation', 'NN'),\n ('simple', 'NN'),\n ('scenario', 'NN'),\n ('source', 'NN'),\n ('preset', 'NN'),\n ('work', 'NN'),\n ('uppercase', 'JJ'),\n ('dictionary', 'JJ'),\n ('known', 'VBN'),\n ('including', 'VBG'),\n ('sometimes', 'RB'),\n ('nlp', 'JJ'),\n ('’', 'JJ'),\n ('one', 'CD'),\n ('spacy', 'NN'),\n ('nine', 'CD'),\n ('capture', 'NN'),\n ('language', 'NN'),\n ('different', 'JJ'),\n ('eg', 'RB'),\n ('social', 'JJ'),\n ('text', 'NN'),\n ('normalization', 'NN'),\n ('developing', 'VBG'),\n ('spelling', 'VBG')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:53:47.884013Z",
     "start_time": "2023-05-15T21:53:47.822473Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
